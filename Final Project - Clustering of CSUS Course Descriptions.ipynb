{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 196K - Final Project - Clustering of CSUS Course Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview and Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is aiming to cluster related CSUS Courses by their catalog descriptions. The project involves getting and parsing the html of the CSUS catalog website for course descriptions. Once the descriptions are obtained, they are passed into Bert for preprocessing and high overview of the descriptions (dimensionality reduction). After this, the 1028-dimeinosnal embedding that represents the pooled understanding of the descriptions is uploaded to TensorFlow's embedding projector to further reduce the dimensions with t-SNE and to view the projection on a 3D Plot. This project utilizes complex datasets, natural language processing, and dimension reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Course Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\travis\\anaconda3\\envs\\aigpu\\lib\\site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\travis\\anaconda3\\envs\\aigpu\\lib\\site-packages (from beautifulsoup4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all subject pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get html page for World Languages & Literatures (WLL)\n"
     ]
    }
   ],
   "source": [
    "catalog_url = 'https://catalog.csus.edu'\n",
    "subject_pages_url = f'{catalog_url}/courses-a-z/'\n",
    "subject_pages_html = requests.get(subject_pages_url).text\n",
    "subject_pages_bs = BeautifulSoup(subject_pages_html, 'html.parser')\n",
    "\n",
    "subject_page_urls = {}\n",
    "subject_div_bs = subject_pages_bs.find('div', {'id': 'atozindex'})\n",
    "for subject_a in subject_div_bs.find_all('a'):\n",
    "    subject_page_ref = subject_a.get('href')\n",
    "    if subject_page_ref is not None:\n",
    "        subject_page_urls[subject_a.get_text()] = catalog_url + subject_page_ref\n",
    "\n",
    "subject_htmls = {}\n",
    "for subject_title, subject_page_url in subject_page_urls.items():\n",
    "    clear_output(wait=True)\n",
    "    print(f'Get html page for {subject_title}')\n",
    "    subject_htmls[subject_title] = requests.get(subject_page_url).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get descriptions for all courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_infos = {}\n",
    "for subject_title, subject_html in subject_htmls.items():\n",
    "    subject_page_bs = BeautifulSoup(subject_html, 'html.parser')\n",
    "    for course_div in subject_page_bs.find_all('div', {'class': 'courseblock'}):\n",
    "        title = course_div.find('span', {'class': 'title'})\n",
    "        # Skip courses with no title\n",
    "        if title is not None:\n",
    "            title = title.get_text()\n",
    "            title = title.strip().replace('\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0', ' ')\n",
    "            description = course_div.find('p', {'class': 'courseblockdesc'})\n",
    "            # Skip courses with no description\n",
    "            if description is not None:\n",
    "                description = description.get_text()\n",
    "                course_infos[title] = {'subject': subject_title, 'description': description}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save course infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('course_infos.json', 'w') as file:\n",
    "    json.dump(course_infos, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load course infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_infos = json.loads(open('course_infos.json', 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Reduce Data Dimensions with Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# assuming tensorflow modules are already installed\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tensorflow import keras\n",
    "\n",
    "# see if using GPU and if so enable memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_5 (KerasLayer)      {'input_mask': (None 0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_6 (KerasLayer)      {'default': (None, 1 335141889   keras_layer_5[0][0]              \n",
      "                                                                 keras_layer_5[0][1]              \n",
      "                                                                 keras_layer_5[0][2]              \n",
      "==================================================================================================\n",
      "Total params: 335,141,889\n",
      "Trainable params: 0\n",
      "Non-trainable params: 335,141,889\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def bert(trainable=False):\n",
    "    preprocess = hub.KerasLayer('assets/bert_en_uncased_preprocess_3')\n",
    "    bert_encoder = hub.KerasLayer('assets/bert_en_wwm_uncased_L-24_H-1024_A-16_3', trainable=trainable)\n",
    "    def _bert(text_input):\n",
    "        x = preprocess(text_input)\n",
    "        x = bert_encoder(x)\n",
    "        pooled_output = x['pooled_output']\n",
    "        sequence_output = x['sequence_output']\n",
    "        return pooled_output, sequence_output\n",
    "    return _bert\n",
    "\n",
    "text_input = keras.layers.Input(shape=(), dtype=tf.string)\n",
    "embedding = bert(trainable=False)(text_input)[0]\n",
    "bert_model = keras.Model(inputs=text_input, outputs=embedding)\n",
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed course descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 90s 595ms/step\n"
     ]
    }
   ],
   "source": [
    "course_titles = []\n",
    "course_descriptions = []\n",
    "for course_title, info in course_infos.items():\n",
    "    course_titles.append(course_title)\n",
    "    course_descriptions.append(info['description'])\n",
    "\n",
    "embedded_course_descriptions = bert_model.predict(course_descriptions, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Embeddings as TSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedded_course_descriptions.tsv', 'w') as tsvfile:\n",
    "    for embedding in embedded_course_descriptions:\n",
    "        tsvfile.write('\\t'.join([str(x) for x in embedding]) + '\\n')\n",
    "        \n",
    "with open('course_metadata.tsv', 'w') as tsvfile:\n",
    "    tsvfile.write('Course Title\\tCourse Subject\\tCourse Description\\n')\n",
    "    for course_title in course_titles:\n",
    "        course_subject = re.sub(r'[^\\x00-\\x7F]+|\\s', ' ', course_infos[course_title]['subject'])\n",
    "        course_description = re.sub(r'[^\\x00-\\x7F]+|\\s', ' ', course_infos[course_title]['description'])\n",
    "        course_title = re.sub(r'[^\\x00-\\x7F]+|\\s', ' ', course_title)\n",
    "        tsvfile.write(f'{course_title}\\t{course_subject}\\t{course_description}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Embedding Dimensions and Plot with TensorFlow Projector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cluster the embeddings I am using [TensorFlow's embedding projector](https://projector.tensorflow.org/). This website requires the previosuly saved tsv files. Once these files are uploaded, I use the T-SNE to further reduce the dimensions to view the descrptions on a 3D plane. The data can be trained and viewed by the projector at this [link](https://projector.tensorflow.org/?config=https://raw.githubusercontent.com/Tiger767/STAT196K-Final-Project/main/projector_config.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After about 1000 iterations of training t-SNE with a perplexity of 5, a learning rate of 10, and supervise 0, the plot below was obtained. ![embedding plot](https://github.com/Tiger767/STAT196K-Final-Project/raw/main/embedding_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Insights\n",
    "Before beginning this project, I suspected that classes from the same subject or similar subjects would cluster together. \n",
    "After looking at the results, a majority of classes from the same subject were not grouped together. This result is better because we already knew the subject for each class and description, so if it were the case, they clustered based on subject, no new insights would have been obtained. I had also hoped later on when working on this project that classes related to similar topics, such as classes dealing with machine learning, would be grouped together; however, this was not the case for the majority of clusters. In the plot above, there are about three main clusters. The first contains a majority of music classes that all have the same description: \"Individual instruction. Music majors only. May be taken for credit four times...\" The second cluster contains \"Special Problems\" courses with descriptions like: \"Individual projects or directed reading...\" The last main cluster contains everything else, though there are smaller clusters within this cluster. One such smaller cluster is a cluster of a couple of classes relating to master's theses. Another smaller cluster that did match the insight of clustering classes with similar topics was a group of physics, chemistry, and mechanical engineering classes that all dealt with physics in some way. One insight I gained from these clusters was that many descriptions are generic and very broad. This insight could have been observed by looking at the descriptions themselves, but the process followed here did highlight this for a couple of cases. Another insight that is a subset of the previous is that many of the generic course descriptions revealed that there are many courses, especially in the music subject, that allow students to instructed themselves. Overall, the plot of the embeddings did not reveal any uniquely significant insights, but it did reveal some insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the project results were not as satisfactory as I would have hoped, but some insights were obtained. I believe if I would have fine-tuned Bert on course catalogs or used the sequence_output instead of the pooled_output, the embedding plot may have revealed more unique insights that other simplistic methods could not have revealed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
